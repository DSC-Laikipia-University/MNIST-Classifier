{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import helper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what one of the images look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method One\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network and look at it's text representation\n",
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "So far we've only been looking at the sigmoid activation function, but in general any function can be used as an activation function. The only requirement is that for a network to approximate a non-linear function, the activation functions must be non-linear. Here are a few more examples of common activation functions: Tanh (hyperbolic tangent), and ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"images/activation.png\" width=700px>\n",
    "\n",
    "In practice, the ReLU function is used almost exclusively as the activation function for hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nn.Sequential`\n",
    "\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general training process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network \n",
    "* Use the network output to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.2825480864754617\n",
      "Training loss: 2.110136639970198\n",
      "Training loss: 1.9477190746427344\n",
      "Training loss: 1.7883581182341586\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        # Solution\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with `torch.load`. And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
